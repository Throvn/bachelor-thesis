


--------------------------------------------------
Starting lstm.py at '2024-10-11 20:17:12.760989'.
Reading './isDaoActiveData(4).json'... Done.
Total training Data: 379
Preparing data for training...
<torch.utils.data.dataloader.DataLoader object at 0x10db68530>
Preparing data for testing...
Trained so far:13
Parameters:
	Num epochs: 60
	Initial learning rate: 0.001
	Patience: 12
	Window size: 60
	Timeseries splits: 3
	Minimum number of timeseries datapoints: 64
Gradient boosting params: 
	{"max_depth": 3, "learning_rate": 0.05, "n_estimators": 100, "objective": "binary:logistic", "eval_metric": "logloss"}
	Creating sequence for '88mph'... [[[  0.49196985   0.           5.        ]
  [  0.45572313   0.          -8.        ]
  [  0.4911416    0.          -9.        ]
  ...
  [  0.46175004   0.           0.        ]
  [  0.43829669   0.          -2.        ]
  [  0.41725131   0.          -2.        ]]

 [[  0.47492268   0.          -3.        ]
  [  0.49196985   0.           5.        ]
  [  0.45572313   0.          -8.        ]
  ...
  [  0.41538501   0.          -7.        ]
  [  0.46175004   0.           0.        ]
  [  0.43829669   0.          -2.        ]]

 [[  0.47756014   0.         -12.        ]
  [  0.47492268   0.          -3.        ]
  [  0.49196985   0.           5.        ]
  ...
  [  0.41951281   0.          -8.        ]
  [  0.41538501   0.          -7.        ]
  [  0.46175004   0.           0.        ]]

 ...

 [[ 41.27795161   2.          99.        ]
  [ 38.28100716   0.          49.        ]
  [ 36.09717438   5.          56.        ]
  ...
  [155.69881273   4.          -4.        ]
  [165.01678531   2.         -74.        ]
  [151.79232673   1.          78.        ]]

 [[ 39.0297078    1.          62.        ]
  [ 41.27795161   2.          99.        ]
  [ 38.28100716   0.          49.        ]
  ...
  [141.19843611   2.          69.        ]
  [155.69881273   4.          -4.        ]
  [165.01678531   2.         -74.        ]]

 [[ 30.0039965    5.          42.        ]
  [ 39.0297078    1.          62.        ]
  [ 41.27795161   2.          99.        ]
  ...
  [150.01742495   0.         228.        ]
  [141.19843611   2.          69.        ]
  [155.69881273   4.          -4.        ]]][0 0 0 ... 1 1 1]
Done.
Training group 0, split 1
	Early stopping at epoch 13
	Y Train Labels:(array([0.], dtype=float32), array([323]))
	Y Val Labels:(array([0.], dtype=float32), array([320]))
Training group 0, split 2
	Y Train Labels:(array([0.], dtype=float32), array([643]))
	Y Val Labels:(array([0., 1.], dtype=float32), array([236,  84]))
Training group 0, split 3
	Early stopping at epoch 13
	Y Train Labels:(array([0., 1.], dtype=float32), array([879,  84]))
	Y Val Labels:(array([1.], dtype=float32), array([320]))
	Creating sequence for 'apeswap-finance'... [[[ 1.13381138e-03  0.00000000e+00 -4.00000000e+00]
  [ 1.14221734e-03  0.00000000e+00  1.00000000e+00]
  [ 1.12974689e-03  2.50000000e+01 -1.30000000e+01]
  ...
  [ 9.15957486e-04  0.00000000e+00  0.00000000e+00]
  [ 9.33242147e-04  5.00000000e+00 -3.00000000e+00]
  [ 9.33496385e-04  2.00000000e+01  1.00000000e+00]]

 [[ 1.17131689e-03  1.00000000e+01  1.00000000e+00]
  [ 1.13381138e-03  0.00000000e+00 -4.00000000e+00]
  [ 1.14221734e-03  0.00000000e+00  1.00000000e+00]
  ...
  [ 9.20087580e-04  0.00000000e+00  3.00000000e+00]
  [ 9.15957486e-04  0.00000000e+00  0.00000000e+00]
  [ 9.33242147e-04  5.00000000e+00 -3.00000000e+00]]

 [[ 1.16652989e-03  4.20000000e+01 -3.00000000e+00]
  [ 1.17131689e-03  1.00000000e+01  1.00000000e+00]
  [ 1.13381138e-03  0.00000000e+00 -4.00000000e+00]
  ...
  [ 8.90803966e-04  1.00000000e+00  1.00000000e+00]
  [ 9.20087580e-04  0.00000000e+00  3.00000000e+00]
  [ 9.15957486e-04  0.00000000e+00  0.00000000e+00]]

 ...

 [[ 1.41326305e+00  5.00000000e+00  4.82000000e+02]
  [ 1.40399441e+00  2.00000000e+01  3.85000000e+02]
  [ 1.36513770e+00  6.00000000e+00  2.58000000e+02]
  ...
  [ 7.22708296e-01  7.00000000e+00  2.55000000e+02]
  [ 7.12519902e-01  6.00000000e+00  5.00000000e+02]
  [ 6.99113116e-01  1.10000000e+01  2.60000000e+02]]

 [[ 1.56555852e+00  2.20000000e+01  2.23000000e+02]
  [ 1.41326305e+00  5.00000000e+00  4.82000000e+02]
  [ 1.40399441e+00  2.00000000e+01  3.85000000e+02]
  ...
  [ 7.40919622e-01  2.90000000e+01  5.75000000e+02]
  [ 7.22708296e-01  7.00000000e+00  2.55000000e+02]
  [ 7.12519902e-01  6.00000000e+00  5.00000000e+02]]

 [[ 1.61220261e+00  2.10000000e+01  3.56000000e+02]
  [ 1.56555852e+00  2.20000000e+01  2.23000000e+02]
  [ 1.41326305e+00  5.00000000e+00  4.82000000e+02]
  ...
  [ 7.73174811e-01  3.00000000e+00  2.80000000e+01]
  [ 7.40919622e-01  2.90000000e+01  5.75000000e+02]
  [ 7.22708296e-01  7.00000000e+00  2.55000000e+02]]][0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Done.
Training group 1, split 1
	Early stopping at epoch 13
	Y Train Labels:(array([0., 1.], dtype=float32), array([ 31, 205]))
	Y Val Labels:(array([1.], dtype=float32), array([235]))
Training group 1, split 2
	Early stopping at epoch 13
	Y Train Labels:(array([0., 1.], dtype=float32), array([ 31, 440]))
	Y Val Labels:(array([1.], dtype=float32), array([235]))
Training group 1, split 3
	Early stopping at epoch 13
	Y Train Labels:(array([0., 1.], dtype=float32), array([ 31, 675]))
	Y Val Labels:(array([1.], dtype=float32), array([235]))
	Creating sequence for '0x'... [[[ 3.84353876e-01  0.00000000e+00 -2.91000000e+02]
  [ 3.75171151e-01  0.00000000e+00 -5.10000000e+01]
  [ 3.77817398e-01  2.40000000e+01 -2.04000000e+02]
  ...
  [ 3.24096377e-01  6.00000000e+00 -5.40000000e+01]
  [ 3.33194135e-01  2.10000000e+01  1.07000000e+02]
  [ 3.38230814e-01  1.00000000e+01  9.20000000e+01]]

 [[ 3.93332087e-01  0.00000000e+00  3.00000000e+01]
  [ 3.84353876e-01  0.00000000e+00 -2.91000000e+02]
  [ 3.75171151e-01  0.00000000e+00 -5.10000000e+01]
  ...
  [ 3.44207307e-01  2.00000000e+00  6.40000000e+01]
  [ 3.24096377e-01  6.00000000e+00 -5.40000000e+01]
  [ 3.33194135e-01  2.10000000e+01  1.07000000e+02]]

 [[ 3.52326743e-01  1.40000000e+01  3.70000000e+01]
  [ 3.93332087e-01  0.00000000e+00  3.00000000e+01]
  [ 3.84353876e-01  0.00000000e+00 -2.91000000e+02]
  ...
  [ 3.26775803e-01  1.40000000e+01  7.00000000e+01]
  [ 3.44207307e-01  2.00000000e+00  6.40000000e+01]
  [ 3.24096377e-01  6.00000000e+00 -5.40000000e+01]]

 ...

 [[ 2.16872000e+00  2.00000000e+01  1.36100000e+03]
  [ 2.14840000e+00  3.30000000e+01  2.04300000e+03]
  [ 1.85208000e+00  6.30000000e+01  2.48000000e+03]
  ...
  [ 6.96557000e-01  5.00000000e+01  2.75000000e+02]
  [ 6.41815000e-01  7.00000000e+01  2.83000000e+02]
  [ 6.45375000e-01  1.08000000e+02 -1.12700000e+03]]

 [[ 1.91458000e+00  1.00000000e+00  9.49000000e+02]
  [ 2.16872000e+00  2.00000000e+01  1.36100000e+03]
  [ 2.14840000e+00  3.30000000e+01  2.04300000e+03]
  ...
  [ 7.84441000e-01  4.60000000e+01  3.05000000e+02]
  [ 6.96557000e-01  5.00000000e+01  2.75000000e+02]
  [ 6.41815000e-01  7.00000000e+01  2.83000000e+02]]

 [[ 1.36357000e+00  0.00000000e+00  1.07000000e+03]
  [ 1.91458000e+00  1.00000000e+00  9.49000000e+02]
  [ 2.16872000e+00  2.00000000e+01  1.36100000e+03]
  ...
  [ 8.87579000e-01  3.40000000e+01  2.99000000e+02]
  [ 7.84441000e-01  4.60000000e+01  3.05000000e+02]
  [ 6.96557000e-01  5.00000000e+01  2.75000000e+02]]][1 1 1 ... 1 1 1]
Done.
Training group 2, split 1
	Early stopping at epoch 13
	Y Train Labels:(array([1.], dtype=float32), array([589]))
	Y Val Labels:(array([1.], dtype=float32), array([586]))
Training group 2, split 2
